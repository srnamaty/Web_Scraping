{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfea35c-f654-4801-8397-0a3ad8d95e8f",
   "metadata": {},
   "source": [
    "# Data cleaning for Job Posting Data:\n",
    "\n",
    "_Author: MatÄ›j Srna_\n",
    "***\n",
    "<img src=\"https://static.wixstatic.com/media/2d21b4_568fb2e8e16e4a3b8dc39ddbd8802708~mv2.png\" style=\"width:350px; height:350px; margin-left: auto; margin-right: auto\" />\n",
    " \n",
    "> _**Disclaimer: This data cleaning is only used for the educational purposes**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25705f52-bc05-48dc-ab33-1f9ece5dbdef",
   "metadata": {},
   "source": [
    "#### Content:\n",
    "1. [Module imports](#Module-imports:)\n",
    "2. [Import of the data from CSV](#Import-of-the-data-from-CSV:)\n",
    "3. [Jobs filtering based on the key words](#Jobs-filtering-based-on-the-key-words:)\n",
    "4. [Deleting all unnecessary job postings from the dataset](#Deleting-all-unnecessary-job-postings-from-the-dataset:)\n",
    "5. [Renaming of all job postings with uncommon names](#Renaming-of-all-job-postings-with-uncommon-names:)\n",
    "6. [Saving the clean dataset to CSV for further analysis](#Saving-the-clean-dataset-to-CSV-for-further-analysis:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485fa4e-6052-4ef6-8113-7706938b8591",
   "metadata": {},
   "source": [
    "### Module imports:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea872f-2c65-40d2-aea8-34efe65cc298",
   "metadata": {},
   "source": [
    "***\n",
    "For this analysis, I had to import several libraries. Mainly I used Pandas to work easaly with Data in DataFrames.\n",
    "\n",
    "Secondly I used the numpy to easily work with data. I used this library to put the date into the list.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18e61a25-389e-49d0-93e1-26898e0f597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "from time import sleep\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2a35b-cdd1-4d36-ba44-4d22465ff67a",
   "metadata": {},
   "source": [
    "### Import of the data from CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ebfcbd-30c0-4a23-b5d5-d2bc183c5ff6",
   "metadata": {},
   "source": [
    "***\n",
    "Here is the data loaded to the Pandas library. The cleaned and summarized data was prepared in the WebScraping tool where all the datasets from each day were merged together into one summarized dataset. To have an overview in size of the table I print the shape of the dataframe.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31f71caa-8a46-437b-a7a9-c276593461b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"DATA/summary_data.csv\"\n",
    "\n",
    "raw_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66817bef-b188-4c7f-ac88-6a195fdf2839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the table is: (2380, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of the table is: {raw_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4454b4-e4ba-4af3-bb9d-47bb1244a7e7",
   "metadata": {},
   "source": [
    "### Jobs filtering based on the key words:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d1486-9087-4600-9601-b8971ed60f66",
   "metadata": {},
   "source": [
    "***\n",
    "This part of the code locates the names of the job postings which does not contain the keywords such as \"Data, Analyst, Machine, Business, Science, and AI\". This data will be deleted because it does not contain the relevant data for this analysis.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ee301fb-7711-44a2-a452-e122e8fc4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srnam\\AppData\\Local\\Temp\\ipykernel_10108\\1873410882.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  to_be_deleted_raw = raw_data.loc[~(raw_data[\"name\"].str.contains(r\"(Data)|(Analyst)|(Machine)|(Business)|(Science)|(AI)\")),\"name\"].unique()\n"
     ]
    }
   ],
   "source": [
    "to_be_deleted_raw = raw_data.loc[~(raw_data[\"name\"].str.contains(r\"(Data)|(Analyst)|(Machine)|(Business)|(Science)|(AI)\")),\"name\"].unique()\n",
    "to_be_deleted_raw = np.ndarray.tolist(to_be_deleted_raw)\n",
    "to_be_deleted = []\n",
    "for n in range(len(to_be_deleted_raw)):\n",
    "    new_value = to_be_deleted_raw[n]\n",
    "    to_be_deleted.append(new_value)\n",
    "\n",
    "#print(to_be_deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d1980-70eb-48c1-8f72-276c4b4d94b1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> To easily and automatically delete all unnecessary data I put all the names into the list. Therefore, I can iterate through this list later on.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaeaa9e-1e54-4456-ae43-7feb5afe236b",
   "metadata": {},
   "source": [
    "### Deleting all unnecessary job postings from the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611aa90f-610d-44e4-98cf-f11858a1de98",
   "metadata": {},
   "source": [
    "***\n",
    "Based on the list created above I iterated the whole data frame to make sure I drop all the unnecessary data. Therefore the dataset is free of all the job postings not related to this analysis. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eac9e725-ba3a-4148-ac14-7666cd7004b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(to_be_deleted)\n",
    "\n",
    "for n in range(length): \n",
    "    #print(to_be_deleted[n])\n",
    "    raw_data.drop(raw_data.index[raw_data[\"name\"]==to_be_deleted[n]], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc4314-6997-4a34-bdce-0c7f24d8cfb4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> To delete all the unnecessary data I iterate through the list with function of drop in pandas dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5996961-1398-4d10-b02d-5b07ce31de6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = raw_data.reset_index(drop=True)\n",
    "clean_data = raw_data.drop_duplicates()\n",
    "#print(raw_data)\n",
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0960ec5b-fab7-43c2-aa58-75c2ffd887da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist                                             1298\n",
       "Senior Data Scientist                                       156\n",
       "Big Data Engineer                                           107\n",
       "Junior Data Scientist                                        57\n",
       "Lead Data Scientist                                          54\n",
       "Data Analyst                                                 24\n",
       "AI Engineer                                                  12\n",
       "Staff Data Scientist                                          4\n",
       "Senior Data Engineer                                          4\n",
       "Data Engineer                                                 3\n",
       "Senior Data Analyst                                           1\n",
       "Business Intelligence Developers                              1\n",
       "Data Crawling Engineer                                        1\n",
       "Lead Data Engineer                                            1\n",
       "Staff Data Engineer                                           1\n",
       "Sap Advanced Business Application Programming Developer       1\n",
       "Name: name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clean_data[\"name\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f3d57-005d-4f5e-81d0-c023938e8342",
   "metadata": {},
   "source": [
    "### Renaming of all job postings with uncommon names:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ca261-d4fe-41a7-bf1c-4762dc7c4fc5",
   "metadata": {},
   "source": [
    "***\n",
    "In this part of the code, all the names of job postings are converted into more common names. Most of the recruiters have tendencies to differ their job offers to attract more applicants, therefore in this part the names with added specifications are converted into common.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c52c39f-d9e2-4c8b-ae24-ca3310df6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear fo all data scientist\n",
    "data_science_rem = [\"Machine Learning Engineer\", \"Embedded SW Engineer - Machine Learning\", \"Machine Learning SW Engineer\", \"Data Science Engineer - ML Projects\", \"Data Scientist, TikTok Creation and Consumption\",\n",
    "                    \"Data Scientist - TikTok Account\", \"Data Scientist - Search\", \"Data Scientist, Ads Analytics\", \"Associate, Data Science\", \"Data Scientist - Relationship discovery\", \"Data Scientist (SAS)\",\n",
    "                    \"Data Scientist, Special Projects\", \"Data Scientist - Hybrid\", \"Data Scientist I\", \"Data Scientist - Risk Data Mining\", \"Data Scientist - Hybrid - Urgent\", \n",
    "                    \"Multi Asset  Quant/Data Scientist role\", \"Data Scientist, Tiktok Ads- Growth Marketing\", \"NLP Researcher (Data Scientist)\", \"Data Scientist, Consultant\", \"Data Science Specialist\",\n",
    "                    \"Data Scientist - Tiktok Ads, Ads Measurement\", \"Data Scientist- W2 ONLY\", \"Data Scientist - Marketing Analytics, Lakeland\", \"Data Scientist - NIH\", \n",
    "                    \"Data Scientist, User Growth - TikTok US - Tech Services\", \"Data Scientist - Pricing\", \"Staff Data Scientist - AI Conversational\", \"Data Scientist/Biostatician- RWE\",\n",
    "                    \"Customer Data Scientist\", \"Data Scientist - North America\", \"Data Scientist, Tiktok Experience\", \"Data Scientist/Statistician\", \"Data Scientist, Tiktok Ads Interfaces\",\n",
    "                    \"Marketing Data Scientist\", \"Staff Data Scientist - Strategy & Insights\", \"Data Scientist Analyst\", \"Data Scientist Intern\", \"Data Scientist, Analytics (Core Product)\",\n",
    "                    \"Associate Data Scientist\", \"Data Scientist/Python Programmer (Hybrid)\", \"Data Scientist / AI Engineer\", \"Entry Level Data Scientist\", \"Director, Data & Technology Scientist\", \n",
    "                    \"Data Scientist - Rare Diseases\", \n",
    "                   ]\n",
    "\n",
    "for n in data_science_rem:\n",
    "    clean_data.loc[clean_data[\"name\"] == n, \"name\"] = \"Data Scientist\"\n",
    "\n",
    "    \n",
    "#clear for all senior data scinetist    \n",
    "data_science_s_rem = [\"Senior Data analyst/Scientist\", \"Senior Data Scientist for Time Series projects\", \"Senior Data Engineer (Store No8 | Health & Wellness)\", \n",
    "                      \"Senior Machine Learning Engineer, Recommendation - US Tech Services\", \"Senior Software Engineer, Machine Learning Platform\", \"Python, Data Science and Machine Learning\",\n",
    "                      \"Data Scientist II, Analytics\", \"Sr. Data Scientist\", \"Senior Data Scientist (Freelance)\", \"Data Scientist II, Product Analytics\", \"Senior Data Scientist for Dataclair AI Centre (m/f)\",\n",
    "                      \"Senior Data Scientist - Banking\", \"Senior Machine Learning Engineer\", \"Data Scientist III, Analytics\", \"Machine Learning Researcher\", \"Data Scientist, Analytics II\", \n",
    "                      \"Data Scientist, Machine Learning\", \"Senior Data Scientist â€“ Healthcare (MCMC)\", \n",
    "                     ]\n",
    "\n",
    "for n in data_science_s_rem:\n",
    "    clean_data.loc[clean_data[\"name\"] == n, \"name\"] = \"Senior Data Scientist\"\n",
    "\n",
    "\n",
    "#clear for all lead data scientist\n",
    "data_science_l_rem = [\"Software developer in the field of Machine Vision\", \"Tech Lead, Machine Learning Engineer, Recommendation & Algorithm\", \"Senior Staff Machine Learning Engineer\", \n",
    "                      \"Lead Data Scientist - Vision Care\", \"Data Science Lead\",\n",
    "    \n",
    "                     ]\n",
    "\n",
    "for n in data_science_l_rem:\n",
    "    clean_data.loc[clean_data[\"name\"] == n, \"name\"] = \"Lead Data Scientist\"\n",
    "\n",
    "\n",
    "#clear for all data analyst\n",
    "data_analyst_rem = [\"Employee Benefits Underwriter - Data Analyst\", \"Data Analyst â€“ Great opportunity in a world of Telecommunications\", \"Fleet Project & Process & Data Analyst\", \n",
    "                    \"DatovÃ½ analytik - oblast Data Governance\", \"Data analytik\", \"Data Analytics\\/Integration Developer\", \"Entry Level Data Analyst\", \n",
    "                    \"Qualitative Data Analyst, Vaccine Equity Partner Engagement\",\n",
    "    \n",
    "                   ]\n",
    "for n in data_analyst_rem:\n",
    "    clean_data.loc[clean_data[\"name\"] == n, \"name\"] = \"Data Analyst\"\n",
    "\n",
    "    \n",
    "#clean for all Big data engineer\n",
    "big_data_rem = [\"Junior Java Software Engineer (Big Data processing and Data Mining)\", \"Full Stack Software Engineer (.NET and react.js), Data & Services, Locations Program\", \n",
    "                \"Data Engineer - Big Data + Digital Marketing\", \"Cloud Data Engineer | Renewable Energy Trading Firm | Boston\", \"Sr. Data Engineer\", \"Data Engineer II\", \n",
    "                \"Java Software Engineer â€“ Big data / Datalake\",\n",
    "                    \n",
    "               ]\n",
    "for n in big_data_rem:\n",
    "    clean_data.loc[clean_data[\"name\"] == n, \"name\"] = \"Big Data Engineer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8febe43-9c27-40ff-bcc4-b774005c6f66",
   "metadata": {},
   "source": [
    "***\n",
    "Here you can see all names of job postings with common names ready for further analysis.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b43ad330-eb2e-4b83-9192-53cf50f7b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist                                             1298\n",
       "Senior Data Scientist                                       156\n",
       "Big Data Engineer                                           107\n",
       "Junior Data Scientist                                        57\n",
       "Lead Data Scientist                                          54\n",
       "Data Analyst                                                 24\n",
       "AI Engineer                                                  12\n",
       "Staff Data Scientist                                          4\n",
       "Senior Data Engineer                                          4\n",
       "Data Engineer                                                 3\n",
       "Senior Data Analyst                                           1\n",
       "Business Intelligence Developers                              1\n",
       "Data Crawling Engineer                                        1\n",
       "Lead Data Engineer                                            1\n",
       "Staff Data Engineer                                           1\n",
       "Sap Advanced Business Application Programming Developer       1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95fb5870-003d-4d7e-a401-eefb9d86b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the table is: (1725, 8)\n"
     ]
    }
   ],
   "source": [
    "# additional drop\n",
    "print(f\"Size of the table is: {clean_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f8730-d263-41a2-a26e-01aedbc8f785",
   "metadata": {},
   "source": [
    "***\n",
    "In this part of the code, I am making sure that all the data is unique and that there are no duplicates in this dataset.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58c0ca59-ce42-4bc7-893a-3ddf7a01d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = clean_data.drop_duplicates()\n",
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd0b1a34-39aa-485d-a28d-909ca4bd88e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name   company_name  ago    contract  location  date   description  link \n",
       "False  False         False  False     False     False  False        False    1725\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clean_data.isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "267bfa58-4638-408e-b600-dc98216a3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HP                           130\n",
       "LHH                           98\n",
       "TikTok                        97\n",
       "NXP Semiconductors            81\n",
       "Ataccama                      68\n",
       "                            ... \n",
       "Experis IT Czech Republic      1\n",
       "DoDo                           1\n",
       "MONETA Money Bank              1\n",
       "ITAB Group                     1\n",
       "PTC                            1\n",
       "Name: company_name, Length: 216, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"company_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "65d57fef-5eba-4677-bf89-c9dbed1566b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.loc[clean_data[\"location\"] == \"Praha\", \"location\"] = \"HlavnÃ­ mÄ›sto Praha, ÄŒesko\"\n",
    "\n",
    "clean_data.loc[clean_data[\"location\"] == \"New York, NY\", \"location\"] = \"New York, United States\"  \n",
    "clean_data.loc[clean_data[\"location\"] == \"New York City Metropolitan Area\", \"location\"] = \"New York, United States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3260c9ce-a6c7-47a5-a841-22f355c3b5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HlavnÃ­ mÄ›sto Praha, ÄŒesko    443\n",
       "Brno                         110\n",
       "Austin, TX                   100\n",
       "New York, United States       75\n",
       "Mountain View, CA             65\n",
       "                            ... \n",
       "Schaumburg, IL                 1\n",
       "ZlÃ­n a okolÃ­                   1\n",
       "HlavnÃ­ mÄ›sto Praha             1\n",
       "Jacksonville, FL               1\n",
       "Denver Metropolitan Area       1\n",
       "Name: location, Length: 114, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d5472-8dbb-495a-8f71-23e4a9eef7c4",
   "metadata": {},
   "source": [
    "***\n",
    "Before saving all of the data from the dataset into the CSV file, I display all web-scraping in descending order based on the date with the number of unique jobs. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04f0592e-faa8-488a-b310-82113505f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-05-15    66\n",
       "2022-05-16    65\n",
       "2022-05-17    90\n",
       "2022-05-18    78\n",
       "2022-05-19    97\n",
       "2022-05-20    65\n",
       "2022-05-21    79\n",
       "2022-05-22    56\n",
       "2022-05-23    51\n",
       "2022-05-24    95\n",
       "2022-05-25    75\n",
       "2022-05-26    85\n",
       "2022-05-27    73\n",
       "2022-05-28    61\n",
       "2022-05-29    54\n",
       "2022-05-30    60\n",
       "2022-05-31    97\n",
       "2022-06-01    69\n",
       "2022-06-02    57\n",
       "2022-06-03    39\n",
       "2022-06-04    78\n",
       "2022-06-05    82\n",
       "2022-06-06    62\n",
       "2022-06-07    38\n",
       "2022-06-08    53\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"date\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1f1b9-4478-411c-9bab-853cec2255a2",
   "metadata": {},
   "source": [
    "### Saving the clean dataset to CSV for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2e3e5f3-b8e1-47bf-a696-495372ffb425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "clean_data.to_csv(\"DATA_IMPORT/clean_data.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a46cf8-6cd0-44a4-858d-cd27a392099a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> All the data was saved into CSV file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208301f8-e568-4807-a1f4-d0b39bb16ce1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<span style=\"color:green\"><p style=\"text-align:right; font-style: italic\"><b>MatÄ›j Srna</b></p></span>\n",
    "<hr></hr>\n",
    "<em>My links:</em>\n",
    "<br>\n",
    "<table style=\"float:left; width: 250px; border-collapse: separate;\">\n",
    "<thead>\n",
    "<tr><th><a href=\"https://www.linkedin.com/in/matejsrna\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://static.wixstatic.com/media/2d21b4_80567ee7301a4a50ada13620eaa1028d~mv2.png\" style=\"width:48px; height:48px\"/></a></th><th><a href=\"https://github.com/srnamaty\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://static.wixstatic.com/media/2d21b4_1d247a3f36384cd8b0eecf23b2010fae~mv2.png\" style=\"width:58px; height:58px\" /></a></th><th><a href=\"https://www.srnamatej.com\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://static.wixstatic.com/media/2d21b4_17665bc36b10443c8446ea225ce8f748~mv2.png\" style=\"width:58px; height:58px\" /></a></th></tr>\n",
    "</thead>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
