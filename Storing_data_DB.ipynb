{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988b5813-7c89-404a-a31b-65dd9a5caaeb",
   "metadata": {},
   "source": [
    "# Importing a CSV file into an Azure MySQL database:\n",
    "\n",
    "_Author: Matěj Srna_\n",
    "***\n",
    "<img src=\"https://static.wixstatic.com/media/2d21b4_ca5a171b85cd4e839032435655ed00ec~mv2.png\" style=\"width:350px; height:350px; margin-left: auto; margin-right: auto\" />\n",
    "\n",
    " \n",
    "> _**Disclaimer: This import to the database is only used for the educational purposes**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02df9a-f0c0-4bbe-91a2-474fb39d8ada",
   "metadata": {},
   "source": [
    "***\n",
    "This part of the code consists of several parts:\n",
    " * first step is to importing the CSV file into the pandas DataFrame,\n",
    " * second step is to clean the table column names and clean it from unnecessary symbols,\n",
    " * third step is to create the table if it does not exist in SQL - statement,\n",
    " * last step is to upload the data into the our database.\n",
    " \n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75913498-645d-4c1b-933c-6111f6e92032",
   "metadata": {},
   "source": [
    "#### Content:\n",
    "1. [Module imports](#Module-imports:)\n",
    "2. [Getting the file path and name](#Getting-the-file-path-and-name:)\n",
    "3. [Reading the data from CSV File which had been cleaned](#Reading-the-data-from-CSV-File-which-had-been-cleaned:)\n",
    "4. [Preview of the MySQL query to create the table with all necessary columns](#Preview-of-the-MySQL-query-to-create-the-table-with-all-necessary-columns: )\n",
    "5. [Connecting to the MySQL database](#Connecting-to-the-MySQL-database:)\n",
    "5. [Saving the clean dataset to CSV for further analysis](#Saving-the-clean-dataset-to-CSV-for-further-analysis:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf12f66-53d8-4397-bc01-c6df042d4f23",
   "metadata": {},
   "source": [
    "### Module imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc6def6-85cc-4175-a7f5-89ee666ed7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import psycopg2\n",
    "import connection_db\n",
    "\n",
    "from time import sleep\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f9589-76d6-4bb1-b8c7-dd9eeee16e73",
   "metadata": {},
   "source": [
    "### Getting the file path and name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12705c1-e150-45bd-ae97-7c940a847752",
   "metadata": {},
   "source": [
    "***\n",
    "Getting the directory to the file which will be imported to the database and it's name. To get the name of the file it's necessary to access the directory where the file is stored. After the accessing, path is return to the previous directory.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2346e921-665f-4e7a-a440-cfc02dc4625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean_data.csv']\n"
     ]
    }
   ],
   "source": [
    "#getting the path to the file with os module with getcwd()\n",
    "try:\n",
    "    os.getcwd()\n",
    "    os.chdir(\"data_import\")\n",
    "except:\n",
    "    pass\n",
    "file_name = os.listdir()\n",
    "file_path = os.getcwd()\n",
    "print(file_name)\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6502e181-3395-4e31-8590-959d555fc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "##os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed214e-a766-4c17-b860-2ae7437154c3",
   "metadata": {},
   "source": [
    "### Reading the data from CSV File which had been cleaned:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7a3ba-39ec-4289-baf5-71740eed7f7a",
   "metadata": {},
   "source": [
    "***\n",
    "Importing data from the clean CSV file into a dataset with file path and filename retrieved by code.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6f2157-2783-4343-8ee1-41af080fb723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>ago</th>\n",
       "      <th>contract</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SEITEQ</td>\n",
       "      <td>Před 2 týdny</td>\n",
       "      <td>Plný úvazek</td>\n",
       "      <td>Hlavní město Praha, Česko</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Analyzovat data pro obchodní potřeby našich zá...</td>\n",
       "      <td>https://cz.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Merkle DACH</td>\n",
       "      <td>Před 3 týdny</td>\n",
       "      <td>Střední služební věk</td>\n",
       "      <td>Hlavní město Praha, Česko</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Data ScientistWe Dream. We Do. We Deliver.As a...</td>\n",
       "      <td>https://cz.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hays</td>\n",
       "      <td>Před 1 týdnem</td>\n",
       "      <td>Střední služební věk</td>\n",
       "      <td>Hlavní město Praha, Česko</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Our customer, technology company has built a s...</td>\n",
       "      <td>https://cz.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Custom Ink</td>\n",
       "      <td>Před 3 týdny</td>\n",
       "      <td>Střední služební věk</td>\n",
       "      <td>Hlavní město Praha, Česko</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Custom Ink is a fast growing e-commerce and ma...</td>\n",
       "      <td>https://cz.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Merkle DACH</td>\n",
       "      <td>Před 1 týdnem</td>\n",
       "      <td>Střední služební věk</td>\n",
       "      <td>Hlavní město Praha, Česko</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>Lead Data ScientistWe Dream. We Do. We Deliver...</td>\n",
       "      <td>https://cz.linkedin.com/jobs/view/lead-data-sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name company_name            ago              contract  \\\n",
       "0         Data Scientist       SEITEQ   Před 2 týdny           Plný úvazek   \n",
       "1         Data Scientist  Merkle DACH   Před 3 týdny  Střední služební věk   \n",
       "2  Senior Data Scientist         Hays  Před 1 týdnem  Střední služební věk   \n",
       "3  Senior Data Scientist   Custom Ink   Před 3 týdny  Střední služební věk   \n",
       "4    Lead Data Scientist  Merkle DACH  Před 1 týdnem  Střední služební věk   \n",
       "\n",
       "                    location        date  \\\n",
       "0  Hlavní město Praha, Česko  2022-05-15   \n",
       "1  Hlavní město Praha, Česko  2022-05-15   \n",
       "2  Hlavní město Praha, Česko  2022-05-15   \n",
       "3  Hlavní město Praha, Česko  2022-05-15   \n",
       "4  Hlavní město Praha, Česko  2022-05-15   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyzovat data pro obchodní potřeby našich zá...   \n",
       "1  Data ScientistWe Dream. We Do. We Deliver.As a...   \n",
       "2  Our customer, technology company has built a s...   \n",
       "3  Custom Ink is a fast growing e-commerce and ma...   \n",
       "4  Lead Data ScientistWe Dream. We Do. We Deliver...   \n",
       "\n",
       "                                                link  \n",
       "0  https://cz.linkedin.com/jobs/view/data-scienti...  \n",
       "1  https://cz.linkedin.com/jobs/view/data-scienti...  \n",
       "2  https://cz.linkedin.com/jobs/view/senior-data-...  \n",
       "3  https://cz.linkedin.com/jobs/view/senior-data-...  \n",
       "4  https://cz.linkedin.com/jobs/view/lead-data-sc...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data with pandas read_csv combining the file path and filename retrieved above\n",
    "data = pd.read_csv(file_path+\"\\\\\"+\"\".join(file_name))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbbac5-c74d-4d97-81b1-9f95a5230ac9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Automatically loads any CSV file which is stored in particular directory.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8302d0-b622-4e78-a896-c11f49cc78e7",
   "metadata": {},
   "source": [
    "***\n",
    "In the code below I prepare the name of the table which will be used in the creation of the MySQL table. Based on the naming conventions for MySQL table the characters must be allowed. Mostly the names cannot consist of symbols and quotation marks. Therefore, I used replace function to remove all the characters which are not allowed. I also do this process with the column names for this table.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2483206-2c9b-4a85-876b-764732aa50f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_data_jobs\n"
     ]
    }
   ],
   "source": [
    "#cleaning the CSV file name for the database import\n",
    "    # lower cases letter\n",
    "    # to remove all the white spaces\n",
    "    # replace -, /, \\\\, # with _\n",
    "    \n",
    "file_name = \"\".join(file_name).replace(\".csv\",\"_jobs\")\n",
    "\n",
    "clean_tbl_name = file_name.lower().replace(\" \", \"_\").replace(\"?\", \"\").replace(\"-\", \"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"%\",\"\").replace(\")\",\"\").replace(r\"(\",\"\").replace(\"?\",\"\")\n",
    "print(clean_tbl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7182ed2-3483-4e8d-94f5-0c2489870f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'company_name', 'ago', 'contract', 'location', 'date',\n",
      "       'description', 'link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#cleaning the table column name for the database import\n",
    "    # lower cases letter\n",
    "    # to remove all the white spaces\n",
    "    # replace -, /, \\\\, # with _\n",
    "    \n",
    "data.columns = [x.lower().replace(\" \", \"_\").replace(\"?\", \"\").replace(\"-\", \"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"%\",\"\").replace(\")\",\"\").replace(r\"(\",\"\").replace(\"?\",\"\") for x in data.columns]\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35388c-0c25-45ee-9692-acd14963d3d6",
   "metadata": {},
   "source": [
    "### Preview of the MySQL query to create the table with all necessary columns: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4ec34-6bfb-4a1e-8491-29a41ccb2de1",
   "metadata": {},
   "source": [
    "```mysql\n",
    "    CREATE TABLE IF NOT EXISTS jobs_summary_data = (\n",
    "        name           varchar,\n",
    "        company_name   varchar,\n",
    "        ago            varchar,\n",
    "        contract       varchar,\n",
    "        location       varchar,\n",
    "        date           date,\n",
    "        description    text CHARACTER SET utf8,\n",
    "        link           varchar,   \n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68b441f-eb76-4a37-9b90-5a9adb8d665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({\"date\": \"datetime64[ns]\"})\n",
    "data = data.astype({\"description\": \"string\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8f1e88-202b-4c75-b105-faa6bbf07d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    object\n",
       "company_name            object\n",
       "ago                     object\n",
       "contract                object\n",
       "location                object\n",
       "date            datetime64[ns]\n",
       "description             string\n",
       "link                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c4955-3fba-4304-8aad-3a992b932879",
   "metadata": {},
   "source": [
    "***\n",
    "In the code below, I change the DataFrame's data type into the MySQL data types. Therefore, I can make a string with all the column names with correct data types. This string is used later on to create automatically the MySQL table.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3921cd-5222-48fa-89bb-4e5e63da7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = {\n",
    "    \"object\": \"varchar(500)\",\n",
    "    \"float64\": \"float\",\n",
    "    \"int64\": \"int\",\n",
    "    \"datetime64[ns]\": \"timestamp(0)\",\n",
    "    \"timesdelta64[ns]\": \"varchar(500)\",\n",
    "    \"string\": \"text CHARACTER SET UTF8MB4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c207611-0039-4fb9-8a62-17f9f6236afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name varchar(500), company_name varchar(500), ago varchar(500), contract varchar(500), location varchar(500), date timestamp(0), description text CHARACTER SET UTF8MB4, link varchar(500)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip (data.columns, data.dtypes.replace(replacement)))\n",
    "con_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed383dc-6532-45c4-9314-a66765f9c634",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> This string contains the transformed names of the columns in DataFrame and combines them with MySQL data types. This string is used for the creation of the MySQL table in the code below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7811a-1d6a-4ea0-84d2-fdd2926740d2",
   "metadata": {},
   "source": [
    "### Connecting to the MySQL database: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c75db-e188-4522-b15c-08e3e740d5a4",
   "metadata": {},
   "source": [
    "***\n",
    "For storing of this data I chose the Azure MySQL database, which is cloud relation database service in the Microsoft cloud. To connect to my database I used mysql.connector module/library.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18279bd3-2e61-4bca-abff-fd864e0232da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "            \"user\": \"msrna\",\n",
    "            \"password\": connection_db.password,\n",
    "            \"database\": \"jobpostingdata\",\n",
    "            \"host\": \"mysqlms12.mysql.database.azure.com\",\n",
    "            \"port\": \"3306\",                              \n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    print(\"Connection established\")\n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"Something is wrong with the user name or password\")\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"Database does not exist\")\n",
    "    else:\n",
    "        print(err)\n",
    "else:\n",
    "    cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62b4c70-2507-476f-bc00-7fa157bfb5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished dropping table (if existed).\n"
     ]
    }
   ],
   "source": [
    "# Drop previous table of same name if one exists\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {clean_tbl_name};\")\n",
    "print(\"Finished dropping table (if existed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f79b61-465d-41e7-845e-8bb8a5e4ee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating table.\n"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "cursor.execute(f\"CREATE TABLE IF NOT EXISTS {clean_tbl_name} ({con_str});\")\n",
    "print(\"Finished creating table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19f2ee-36ca-4588-909a-51d99fda72d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> The string created above contains the transformed names of the columns in DataFrame combined with MySQL data types. With this string, the MySQL table is created.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38958da-9550-42c2-8721-a489b12fa8c1",
   "metadata": {},
   "source": [
    "***\n",
    "In the code below, I combined the MySQL query string with iterating in the data frame containing all the web scraped data. Therefore, I am able to load all the data into the MySQL database. I also used the tqdm progress bar to show how the loading progresses.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37993c0-a86c-4366-838f-2e7f784af44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading 1725 of rows into database: 100%|████████████████████████████████████████| 1725/1725 [00:51<00:00, 33.41it/s]\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(data.index)\n",
    "index = 0\n",
    "\n",
    "try:\n",
    "    with tqdm(total=num_rows) as pbar:\n",
    "        pbar.set_description(\"Uploading %s of rows into database\" % num_rows)\n",
    "        for (row, rs) in data.iterrows():\n",
    "            index += 1\n",
    "            name = rs[0]\n",
    "            company_name = rs[1].replace(\"'\",\"\").replace(\"’\",\"\")\n",
    "            ago = rs[2]\n",
    "            contract = rs[3]\n",
    "            location = rs[4]\n",
    "            date = str(rs[5])\n",
    "            description = rs[6].replace(\"'\",\" \").replace(\"$\",\"\").replace(\"’\",\"\")\n",
    "            link =  rs[7]\n",
    "            query=f\"INSERT IGNORE INTO {clean_tbl_name} \\\n",
    "        VALUES (\"+\"'\"+name+\"'\"+\", \"+\"'\"+company_name+\"'\"+\", \"+\"'\"+ago+\"'\"+\",\"+\"'\"+contract+\"'\"+\"\\\n",
    "        , \"+\"'\"+location+\"'\"+\", \"+\"'\"+date+\"'\"+\", \"+\"'\"+description+\"'\"+\", \"+\"'\"+link+\"'\"+\");\"\n",
    "            cursor.execute(query)\n",
    "            pbar.update(1)\n",
    "            \n",
    "except:\n",
    "    pass\n",
    "conn.commit()\n",
    "#print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f9408-f2f3-4b06-8b08-7782676905b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> To see the progress of data loading into the database I used tqdm bar to show progress.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d62768-eac5-4314-bf38-6e2de358509f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cursor closed\n",
      "Database closed\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "try:\n",
    "    conn.commit()\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    cursor.close()\n",
    "    print(\"Cursor closed\")\n",
    "except:\n",
    "    pass\n",
    "if conn.is_connected():\n",
    "    conn.close()\n",
    "    print(\"Database closed\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cbb3fe-d87e-476e-ae41-34a63a7db13c",
   "metadata": {},
   "source": [
    "### Accessing the loaded data from the database:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5eee2f-2b3f-4516-8461-70e79033d69d",
   "metadata": {},
   "source": [
    "***\n",
    "To varify if the data was successfuly loaded, I access the database and select the data using the MySQL query:\n",
    "```mysql\n",
    "SELECT NAME, COUNT(NAME) FROM clean_data_jobs GROUP BY NAME ORDER BY COUNT(NAME) DESC;\n",
    "\n",
    "```\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a46e64f-09b2-43ba-836c-62eb4797cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "            \"user\": \"msrna\",\n",
    "            \"password\": connection_db.password,\n",
    "            \"database\": \"jobpostingdata\",\n",
    "            \"host\": \"mysqlms12.mysql.database.azure.com\",\n",
    "            \"port\": \"3306\",                              \n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    print(\"Connection established\")\n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"Something is wrong with the user name or password\")\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"Database does not exist\")\n",
    "    else:\n",
    "        print(err)\n",
    "else:\n",
    "    cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2795a93-94f6-4a5d-b392-fc47c11e9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT NAME, COUNT(NAME) FROM clean_data_jobs GROUP BY NAME ORDER BY COUNT(NAME) DESC;\")\n",
    "names = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6137f29-38cc-4459-b87f-633611d11f84",
   "metadata": {},
   "source": [
    "***\n",
    "Data is loaded by MySQL query using the cursor execute and function fetchall into the variable name. To see the data more clearly I put it into the pandas DataFrame with specified column names.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5b8c93-25b1-4560-b2df-591998459248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sap Advanced Business Application Programming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Staff Data Engineer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Crawling Engineer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Intelligence Developers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Names  Count\n",
       "0                                      Data Scientist   1298\n",
       "1                               Senior Data Scientist    156\n",
       "2                                   Big Data Engineer    107\n",
       "3                               Junior Data Scientist     57\n",
       "4                                 Lead Data Scientist     54\n",
       "5                                        Data Analyst     24\n",
       "6                                         AI Engineer     12\n",
       "7                                Senior Data Engineer      4\n",
       "8                                Staff Data Scientist      4\n",
       "9                                       Data Engineer      3\n",
       "10  Sap Advanced Business Application Programming ...      1\n",
       "11                                Staff Data Engineer      1\n",
       "12                                 Lead Data Engineer      1\n",
       "13                             Data Crawling Engineer      1\n",
       "14                   Business Intelligence Developers      1\n",
       "15                                Senior Data Analyst      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_d = pd.DataFrame(names, columns=[\"Names\", \"Count\"])\n",
    "names_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3ba3f-bca4-4514-af0f-f642f50aa7eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> The data was successfuly loaded and visualized in table.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99c3571b-b0f4-4916-8bd5-ea106fe02431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cursor closed\n",
      "Database closed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cursor.close()\n",
    "    print(\"Cursor closed\")\n",
    "except:\n",
    "    pass\n",
    "if conn.is_connected():\n",
    "    conn.close()\n",
    "    print(\"Database closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23800e69-cfb6-4c8c-a7eb-2b38051a9302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1fec2e5-645e-4735-9857-0665823523d5",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<span style=\"color:green\"><p style=\"text-align:right; font-style: italic\"><b>Matěj Srna</b></p></span>\n",
    "<hr></hr>\n",
    "<em>My links:</em>\n",
    "<br>\n",
    "<table style=\"float:left; width: 250px; border-collapse: separate;\">\n",
    "<thead>\n",
    "<tr><th><a href=\"https://www.linkedin.com/in/matejsrna\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://static.wixstatic.com/media/2d21b4_80567ee7301a4a50ada13620eaa1028d~mv2.png\" style=\"width:48px; height:48px\"/></a></th><th><a href=\"https://github.com/srnamaty\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://static.wixstatic.com/media/2d21b4_1d247a3f36384cd8b0eecf23b2010fae~mv2.png\" style=\"width:58px; height:58px\" /></a></th><th><a href=\"https://www.srnamatej.com\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://static.wixstatic.com/media/2d21b4_17665bc36b10443c8446ea225ce8f748~mv2.png\" style=\"width:58px; height:58px\" /></a></th></tr>\n",
    "</thead>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
